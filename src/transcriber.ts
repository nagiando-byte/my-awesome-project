/**
 * ZooméŒ²ç”»ã®è‡ªå‹•æ–‡å­—èµ·ã“ã—ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
 * OpenAI Whisper APIã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
 */

import OpenAI from 'openai';
import ffmpeg from 'fluent-ffmpeg';
import * as fs from 'fs';
import * as path from 'path';
import { promises as fsPromises } from 'fs';

export interface TranscriptionOptions {
  /** å…¥åŠ›å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ */
  inputPath: string;
  /** å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆï¼‰ */
  outputPath?: string;
  /** è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•æ¤œå‡ºï¼‰ */
  language?: string;
  /** ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å«ã‚ã‚‹ã‹ */
  includeTimestamps?: boolean;
}

export interface TranscriptionResult {
  /** æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ */
  text: string;
  /** å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ */
  outputPath: string;
  /** å‡¦ç†æ™‚é–“ï¼ˆç§’ï¼‰ */
  processingTime: number;
}

export class ZoomTranscriber {
  private openai: OpenAI;
  private tempDir: string;

  constructor(apiKey?: string) {
    this.openai = new OpenAI({
      apiKey: apiKey || process.env.OPENAI_API_KEY,
    });
    this.tempDir = path.join(process.cwd(), '.temp');
  }

  /**
   * å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡º
   */
  private async extractAudio(videoPath: string): Promise<string> {
    // ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    if (!fs.existsSync(this.tempDir)) {
      await fsPromises.mkdir(this.tempDir, { recursive: true });
    }

    const audioPath = path.join(
      this.tempDir,
      `audio_${Date.now()}.mp3`
    );

    return new Promise((resolve, reject) => {
      console.log('ğŸµ éŸ³å£°ã‚’æŠ½å‡ºä¸­...');
      ffmpeg(videoPath)
        .output(audioPath)
        .audioCodec('libmp3lame')
        .audioQuality(2) // é«˜å“è³ª
        .on('end', () => {
          console.log('âœ… éŸ³å£°æŠ½å‡ºå®Œäº†');
          resolve(audioPath);
        })
        .on('error', (err) => {
          console.error('âŒ éŸ³å£°æŠ½å‡ºã‚¨ãƒ©ãƒ¼:', err);
          reject(err);
        })
        .run();
    });
  }

  /**
   * éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Whisper APIã§æ–‡å­—èµ·ã“ã—
   */
  private async transcribeAudio(
    audioPath: string,
    language?: string
  ): Promise<string> {
    console.log('ğŸ¤ æ–‡å­—èµ·ã“ã—ä¸­...');

    const audioFile = fs.createReadStream(audioPath);

    const response = await this.openai.audio.transcriptions.create({
      file: audioFile,
      model: 'whisper-1',
      language: language || 'ja', // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ—¥æœ¬èª
      response_format: 'verbose_json',
      timestamp_granularities: ['segment'],
    });

    console.log('âœ… æ–‡å­—èµ·ã“ã—å®Œäº†');
    return JSON.stringify(response, null, 2);
  }

  /**
   * æ–‡å­—èµ·ã“ã—çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
   */
  private async saveTranscription(
    text: string,
    outputPath: string
  ): Promise<void> {
    const outputDir = path.dirname(outputPath);
    if (!fs.existsSync(outputDir)) {
      await fsPromises.mkdir(outputDir, { recursive: true });
    }

    await fsPromises.writeFile(outputPath, text, 'utf-8');
    console.log(`ğŸ’¾ æ–‡å­—èµ·ã“ã—çµæœã‚’ä¿å­˜: ${outputPath}`);
  }

  /**
   * ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
   */
  private async cleanup(audioPath: string): Promise<void> {
    try {
      if (fs.existsSync(audioPath)) {
        await fsPromises.unlink(audioPath);
        console.log('ğŸ§¹ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ');
      }
    } catch (error) {
      console.warn('âš ï¸  ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—:', error);
    }
  }

  /**
   * ZooméŒ²ç”»ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰
   */
  async transcribe(
    options: TranscriptionOptions
  ): Promise<TranscriptionResult> {
    const startTime = Date.now();

    // å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    if (!fs.existsSync(options.inputPath)) {
      throw new Error(`å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: ${options.inputPath}`);
    }

    // å‡ºåŠ›ãƒ‘ã‚¹ã®æ±ºå®š
    const outputPath =
      options.outputPath ||
      path.join(
        path.dirname(options.inputPath),
        `${path.basename(options.inputPath, path.extname(options.inputPath))}_transcript.json`
      );

    console.log('ğŸš€ ZooméŒ²ç”»ã®æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹');
    console.log(`ğŸ“¹ å…¥åŠ›: ${options.inputPath}`);
    console.log(`ğŸ“„ å‡ºåŠ›: ${outputPath}`);

    let audioPath = '';

    try {
      // 1. éŸ³å£°æŠ½å‡º
      audioPath = await this.extractAudio(options.inputPath);

      // 2. æ–‡å­—èµ·ã“ã—
      const transcriptionText = await this.transcribeAudio(
        audioPath,
        options.language
      );

      // 3. çµæœã‚’ä¿å­˜
      await this.saveTranscription(transcriptionText, outputPath);

      // 4. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      await this.cleanup(audioPath);

      const processingTime = (Date.now() - startTime) / 1000;

      console.log(`âœ… å®Œäº†ï¼ (å‡¦ç†æ™‚é–“: ${processingTime.toFixed(2)}ç§’)`);

      return {
        text: transcriptionText,
        outputPath,
        processingTime,
      };
    } catch (error) {
      // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      if (audioPath) {
        await this.cleanup(audioPath);
      }
      throw error;
    }
  }

  /**
   * ãƒãƒƒãƒå‡¦ç†: è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬æ–‡å­—èµ·ã“ã—
   */
  async transcribeBatch(
    inputPaths: string[],
    options?: Partial<TranscriptionOptions>
  ): Promise<TranscriptionResult[]> {
    console.log(`ğŸ“¦ ãƒãƒƒãƒå‡¦ç†é–‹å§‹: ${inputPaths.length}ãƒ•ã‚¡ã‚¤ãƒ«`);

    const results: TranscriptionResult[] = [];

    for (let i = 0; i < inputPaths.length; i++) {
      console.log(`\n[${i + 1}/${inputPaths.length}] ${inputPaths[i]}`);
      try {
        const result = await this.transcribe({
          ...options,
          inputPath: inputPaths[i],
        });
        results.push(result);
      } catch (error) {
        console.error(`âŒ ã‚¨ãƒ©ãƒ¼: ${inputPaths[i]}`, error);
      }
    }

    console.log(`\nâœ… ãƒãƒƒãƒå‡¦ç†å®Œäº†: ${results.length}/${inputPaths.length}ä»¶æˆåŠŸ`);

    return results;
  }
}

